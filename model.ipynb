{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Below is the XGBoost regression model used for predictive analytics, followed by some of the previous versions\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Mean Squared Error (MSE): 1.601085067077502\n",
      "Root Mean Squared Error (RMSE): 1.2653399017961546\n",
      "Relative RMSE: 26.55%\n",
      "Mean Demand: 4.76569143824976\n",
      "Train Score: 0.7903385660989202\n",
      "Test Score: 0.7883476063211605\n",
      "Execution time: 317.209349155426 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = df.drop('Order_Demand', axis=1)\n",
    "y = df['Order_Demand'].astype(float)\n",
    "\n",
    "# Assign sample weights based on quantiles of demand\n",
    "quantiles = np.percentile(y, [25, 50, 75])\n",
    "weights = np.ones_like(y)\n",
    "# Assign higher weights to lower and upper quantiles (underrepresented demand levels)\n",
    "weights[y <= quantiles[0]] = 1.5  # 1st quartile (low demand)\n",
    "weights[y >= quantiles[2]] = 1.5  # 4th quartile (high demand)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test, weights_train, weights_test = train_test_split(X, y, weights, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define hyperparameter space for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200],  # Number of trees\n",
    "    'learning_rate': [0.01, 0.05, 0.1],  # Learning rate\n",
    "    'max_depth': [3, 4, 5],  # Max depth of trees\n",
    "    'min_child_weight': [1, 2, 3],  # Minimum sum of instance weight needed in a child\n",
    "    'subsample': [0.8, 0.9, 1.0],  # Subsample ratio of the training data\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],  # Subsample ratio of features per tree\n",
    "    'reg_alpha': [0.01, 0.05, 0.1],  # L1 regularization term\n",
    "    'reg_lambda': [0.5, 1.0, 1.5]    # L2 regularization term\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model, \n",
    "    param_distributions=param_grid, \n",
    "    n_iter=50, \n",
    "    cv=3, \n",
    "    scoring='neg_mean_squared_error', \n",
    "    verbose=1, \n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "# Fit the model with the training data and weights\n",
    "random_search.fit(X_train, y_train, sample_weight=weights_train)\n",
    "\n",
    "# Extract the best model\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Evaluate the model\n",
    "train_score = best_model.score(X_train, y_train)\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "\n",
    "# Predict using the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate performance metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "relative_rmse = (rmse / y_test.mean()) * 100\n",
    "mean_demand = y_test.mean()\n",
    "\n",
    "# Output results\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Relative RMSE: {relative_rmse:.2f}%\")\n",
    "print(f\"Mean Demand: {mean_demand}\")\n",
    "print(f\"Train Score: {train_score}\")\n",
    "print(f\"Test Score: {test_score}\")\n",
    "\n",
    "# Additional evaluation\n",
    "evaluation_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "evaluation_df.head()\n",
    "\n",
    "print(f\"Execution time: {time.time() - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"combined weight loss with randomsearchCV k fold validation, 0.1:26.5%. best result\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Relative RMSE of 27% is generally considered acceptable, for this specific use case it could require some checks:\n",
    "\n",
    "Financial Impact Assessment with Cost of Stockouts\n",
    "Inventory Management KPIs for Service Level and Inventory Turnover\n",
    "Safety Stock Calculation\n",
    "Impact on Lead Time\n",
    "Sensitivity Analysis\n",
    "\n",
    "In retail, a relative RMSE between 10% and 30% is generally considered acceptable, \n",
    "though depends on the complexity of the product mix and seasonality.\n",
    "For an outdoor equipment shop, where demand can be highly seasonal (e.g., spikes during spring and summer, as well as before holidays), a relative RMSE near 25% is reasonable.\n",
    "\n",
    "Product Types: Outdoor equipment can range from low-cost, high-volume items (like camping gear) to high-cost, low-volume items (like tents, kayaks, and bikes). Forecasting for high-cost items usually tolerates slightly higher errors due to the lower volume of purchases, while low-cost, high-volume items typically require more precise forecasting.\n",
    "Seasonality: Because the demand for outdoor equipment is highly seasonal, seasonality adjustments are crucial. A relative RMSE of ~26.8% might still be acceptable during off-season times if it's more accurate during peak seasons.\n",
    "\n",
    "Run Simulations to estimate the financial impact of forecasting errors on inventory costs and lost sales due to stockouts or overstocking. (NOT WITHIN SCOPE OF PROJECT)\n",
    "Benchmark RMSE against any available industry data or past forecasting methods (moving averages, ARIMA, etc.) to see how much improvement the model brings.\n",
    "Adjust Safety Stock based on the RMSE to balance procurement efficiency with service level.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "below are some previous versions of simpler XGBoost models, they have marginally worse accuracy but much faster run times. \n",
    "It is ucertain how any of these perform on larger datsets, testing of this is not within the scope of this project, so I have left them as part of the notebook. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 1.632817576975212\n",
      "Root Mean Squared Error (RMSE): 1.277817505348558\n",
      "Relative RMSE: 26.81%\n",
      "Mean Demand: 4.76569143824976\n",
      "Train Score: 0.7864026698230477\n",
      "Test Score: 0.7841527875601891\n",
      "Execution time: 2.983020544052124 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = df.drop('Order_Demand', axis=1)\n",
    "y = df['Order_Demand'].astype(float)\n",
    "\n",
    "# Assign sample weights based on quantiles of demand\n",
    "quantiles = np.percentile(y, [25, 50, 75])\n",
    "weights = np.ones_like(y)\n",
    "# Assign higher weights to lower and upper quantiles (underrepresented demand levels)\n",
    "weights[y <= quantiles[0]] = 1.5  # 1st quartile (low demand)\n",
    "weights[y >= quantiles[2]] = 1.5  # 4th quartile (high demand)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test, weights_train, weights_test = train_test_split(X, y, weights, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train an XGBoost model with sample weights\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1)\n",
    "model.fit(X_train, y_train, sample_weight=weights_train)\n",
    "\n",
    "# Evaluate the model\n",
    "train_score = model.score(X_train, y_train)\n",
    "test_score = model.score(X_test, y_test)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "relative_rmse = (rmse / y_test.mean()) * 100\n",
    "mean_demand = y_test.mean()\n",
    "\n",
    "# Output results\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Relative RMSE: {relative_rmse:.2f}%\")\n",
    "print(f\"Mean Demand: {mean_demand}\")\n",
    "print(f\"Train Score: {train_score}\")\n",
    "print(f\"Test Score: {test_score}\")\n",
    "\n",
    "# Additional evaluation\n",
    "evaluation_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "evaluation_df.head()\n",
    "print(f\"Execution time: {time.time() - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "weight loss function, with log transformation to highly skewed order demand\n",
    "took relative RMSE down to 0.1: 26%\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Mean Squared Error (MSE): 1.6121421196100456\n",
      "Root Mean Squared Error (RMSE): 1.2697015868344994\n",
      "Relative RMSE: 26.64%\n",
      "Mean Demand: 4.76569143824976\n",
      "Execution time: 257.434823513031 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = df.drop('Order_Demand', axis=1)\n",
    "y = df['Order_Demand'].astype(float)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 150, 200],  # Narrower range\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 4, 5],  # Fine-tuning smaller ranges\n",
    "    'min_child_weight': [1, 2, 3],  # Narrower range\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'reg_alpha': [0.01, 0.05, 0.1],  # More regularization\n",
    "    'reg_lambda': [0.5, 1.0, 1.5]    # More regularization\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb_model, \n",
    "    param_distributions=param_grid, \n",
    "    n_iter=50, \n",
    "    cv=3, \n",
    "    scoring='neg_mean_squared_error', \n",
    "    verbose=1, \n",
    "    n_jobs=1\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Train the best model from GridSearchCV with early stopping\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# fit with early stopping using the validation set\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "train_score = best_model.score(X_train, y_train)\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "relative_rmse = (rmse / y_test.mean()) * 100\n",
    "mean_demand = y_test.mean()\n",
    "\n",
    "# Output the results\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Relative RMSE: {relative_rmse:.2f}%\")\n",
    "print(f\"Mean Demand: {mean_demand}\")\n",
    "\n",
    "# Additional evaluation\n",
    "evaluation_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "evaluation_df.head()\n",
    "print(f\"Execution time: {time.time() - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "just randomsearchCV, 0.1:26.6%\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
